{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30665,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"#**Face Generator Using GANS**","metadata":{}},{"cell_type":"markdown","source":"#**Application of GANs**\n1. Generating fake faces\n2. Generate Examples for Image Datasets3. Face Aging\n4. Super Resolution\n5. Image-to-Image Translation\n6. Photos to Emojis\n7.Text to image Translation\n8. Generate Cartoon characters","metadata":{}},{"cell_type":"code","source":"!unzip /kaggle/working/https:/www.kaggle.com/datasets/ashishjangra27/face-mask-12k-images-dataset/face-mask-12k-images-dataset.zip","metadata":{"execution":{"iopub.status.busy":"2024-03-19T13:37:19.919837Z","iopub.execute_input":"2024-03-19T13:37:19.920130Z","iopub.status.idle":"2024-03-19T13:37:25.112739Z","shell.execute_reply.started":"2024-03-19T13:37:19.920104Z","shell.execute_reply":"2024-03-19T13:37:25.111453Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import re\nimport cv2\nimport numpy as np\nfrom tqdm import tqdm\nimport tensorflow as tf\nfrom tensorflow import keras\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras import layers","metadata":{"execution":{"iopub.status.busy":"2024-03-19T13:37:25.114257Z","iopub.execute_input":"2024-03-19T13:37:25.115000Z","iopub.status.idle":"2024-03-19T13:37:37.486163Z","shell.execute_reply.started":"2024-03-19T13:37:25.114968Z","shell.execute_reply":"2024-03-19T13:37:37.485051Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##**Preprocess Dataset**","metadata":{}},{"cell_type":"code","source":"img_size = 128\nall_imgs = []\n\nimg_path = \"/kaggle/working/Face Mask Dataset/Train/WithoutMask\"\nfiles = sorted(os.listdir(img_path))\n\nfor i in tqdm(files):\n    img = cv2.imread(img_path + \"/\" + i, 1)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    img = cv2.resize(img, (img_size, img_size))\n    img = (img - 127.5)  / 127.5\n    img = img.astype(float)\n    all_imgs.append(keras.utils.img_to_array(img))","metadata":{"execution":{"iopub.status.busy":"2024-03-19T13:37:37.489235Z","iopub.execute_input":"2024-03-19T13:37:37.490407Z","iopub.status.idle":"2024-03-19T13:37:41.568957Z","shell.execute_reply.started":"2024-03-19T13:37:37.490375Z","shell.execute_reply":"2024-03-19T13:37:41.567926Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_img(ran):\n    plt.figure(figsize=(10,10))\n    plt.title(\"Real images\", fontsize = 35)\n\n    for i in range(ran * ran):\n        plt.subplot(ran, ran, i+1)\n        plt.imshow(all_imgs[i] * 0.5 + 0.5)\n        plt.xticks([])\n        plt.yticks([])\n    plt.show()\n\n\nplot_img(6)","metadata":{"execution":{"iopub.status.busy":"2024-03-19T13:37:41.570451Z","iopub.execute_input":"2024-03-19T13:37:41.570945Z","iopub.status.idle":"2024-03-19T13:37:43.616040Z","shell.execute_reply.started":"2024-03-19T13:37:41.570909Z","shell.execute_reply":"2024-03-19T13:37:43.615065Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##**Convert Dataset to Tensor Slices**","metadata":{}},{"cell_type":"code","source":"batch_size = 32\nbuffer_size = 60000\ndataset = tf.data.Dataset.from_tensor_slices(all_imgs).shuffle(buffer_size).batch(batch_size)","metadata":{"execution":{"iopub.status.busy":"2024-03-19T13:37:43.617248Z","iopub.execute_input":"2024-03-19T13:37:43.617567Z","iopub.status.idle":"2024-03-19T13:40:28.125178Z","shell.execute_reply.started":"2024-03-19T13:37:43.617542Z","shell.execute_reply":"2024-03-19T13:40:28.124115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##**Build Generator Model**","metadata":{}},{"cell_type":"code","source":"latent_dim = 100\n\n\ndef Generator():\n    model = keras.Sequential()\n    model.add(keras.Input(shape = (latent_dim,)))\n    model.add(layers.Dense(128*128*3, use_bias=False))\n    model.add(layers.Reshape((128,128,3)))\n    # downsampling\n    model.add(layers.Conv2D(128,4, strides=1, padding='same',kernel_initializer='he_normal', use_bias=False))\n    model.add(layers.Conv2D(128,4, strides=2, padding='same',kernel_initializer='he_normal', use_bias=False))\n    model.add(layers.BatchNormalization())\n    model.add(layers.LeakyReLU())\n    model.add(layers.Conv2D(256,4, strides=1, padding='same',kernel_initializer='he_normal', use_bias=False))\n    model.add(layers.Conv2D(256,4, strides=2, padding='same',kernel_initializer='he_normal', use_bias=False))\n    model.add(layers.BatchNormalization())\n    model.add(layers.LeakyReLU())\n    model.add(layers.Conv2DTranspose(512, 4, strides=1,padding='same',kernel_initializer='he_normal',use_bias=False))\n    model.add(layers.Conv2D(512,4, strides=2, padding='same',kernel_initializer='he_normal', use_bias=False))\n\n    model.add(layers.LeakyReLU())\n    #upsampling\n    model.add(layers.Conv2DTranspose(512, 4, strides=1,padding='same',kernel_initializer='he_normal',use_bias=False))\n    model.add(layers.Conv2DTranspose(512, 4, strides=2,padding='same',kernel_initializer='he_normal',use_bias=False))\n    model.add(layers.BatchNormalization())\n    model.add(layers.LeakyReLU())\n    model.add(layers.Conv2DTranspose(256, 4, strides=1,padding='same',kernel_initializer='he_normal',use_bias=False))\n    model.add(layers.Conv2DTranspose(256, 4, strides=2,padding='same',kernel_initializer='he_normal',use_bias=False))\n    model.add(layers.BatchNormalization())\n\n    model.add(layers.Conv2DTranspose(128, 4, strides=2,padding='same',kernel_initializer='he_normal',use_bias=False))\n    model.add(layers.Conv2DTranspose(128, 4, strides=1,padding='same',kernel_initializer='he_normal',use_bias=False))\n    model.add(layers.BatchNormalization())\n    model.add(layers.Conv2DTranspose(3,4,strides = 1, padding = 'same',activation = 'tanh'))\n\n\n\n    return model","metadata":{"execution":{"iopub.status.busy":"2024-03-19T13:40:28.127399Z","iopub.execute_input":"2024-03-19T13:40:28.127726Z","iopub.status.idle":"2024-03-19T13:40:28.142495Z","shell.execute_reply.started":"2024-03-19T13:40:28.127699Z","shell.execute_reply":"2024-03-19T13:40:28.141615Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"generator = Generator()\ngenerator.summary()","metadata":{"execution":{"iopub.status.busy":"2024-03-19T13:40:28.143834Z","iopub.execute_input":"2024-03-19T13:40:28.144407Z","iopub.status.idle":"2024-03-19T13:40:28.532904Z","shell.execute_reply.started":"2024-03-19T13:40:28.144375Z","shell.execute_reply":"2024-03-19T13:40:28.532009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"noise = np.random.normal(-1,1,(1,100))\nimg = generator(noise)\nplt.imshow(img[0,:,:,0])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-03-19T13:40:28.534250Z","iopub.execute_input":"2024-03-19T13:40:28.534713Z","iopub.status.idle":"2024-03-19T13:40:30.456893Z","shell.execute_reply.started":"2024-03-19T13:40:28.534679Z","shell.execute_reply":"2024-03-19T13:40:30.455946Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##**Build Discriminator Model**","metadata":{}},{"cell_type":"code","source":"def Discriminator():\n    model = keras.Sequential()\n    model.add(keras.Input(shape = (img_size, img_size, 3)))\n    model.add(layers.Conv2D(128, 4, strides = 2, padding = \"same\", kernel_initializer = \"he_normal\", use_bias = False))\n    model.add(layers.BatchNormalization())\n    model.add(layers.LeakyReLU())\n    model.add(layers.Dropout(0.3))\n\n    model.add(layers.Conv2D(128, 4, strides = 2, padding = \"same\", kernel_initializer = \"he_normal\", use_bias = False))\n    model.add(layers.BatchNormalization())\n    model.add(layers.LeakyReLU())\n    model.add(layers.Dropout(0.3))\n\n    model.add(layers.Conv2D(256, 4, strides = 2, padding = \"same\", kernel_initializer = \"he_normal\", use_bias = False))\n    model.add(layers.BatchNormalization())\n    model.add(layers.LeakyReLU())\n    model.add(layers.Dropout(0.3))\n\n    model.add(layers.Conv2D(256, 4, strides = 2, padding = \"same\", kernel_initializer = \"he_normal\", use_bias = False))\n    model.add(layers.BatchNormalization())\n    model.add(layers.LeakyReLU())\n    model.add(layers.Dropout(0.3))\n\n    model.add(layers.Conv2D(512, 4, strides = 2, padding = \"same\", kernel_initializer = \"he_normal\", use_bias = False))\n    model.add(layers.LeakyReLU())\n    model.add(layers.Dropout(0.3))\n\n    model.add(layers.Flatten())\n    model.add(layers.Dense(1, activation = \"sigmoid\"))\n\n    return model","metadata":{"execution":{"iopub.status.busy":"2024-03-19T13:40:30.458309Z","iopub.execute_input":"2024-03-19T13:40:30.458769Z","iopub.status.idle":"2024-03-19T13:40:30.473664Z","shell.execute_reply.started":"2024-03-19T13:40:30.458732Z","shell.execute_reply":"2024-03-19T13:40:30.472602Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"discriminator = Discriminator()\ndiscriminator.summary()","metadata":{"execution":{"iopub.status.busy":"2024-03-19T13:40:30.476792Z","iopub.execute_input":"2024-03-19T13:40:30.477053Z","iopub.status.idle":"2024-03-19T13:40:30.750762Z","shell.execute_reply.started":"2024-03-19T13:40:30.477030Z","shell.execute_reply":"2024-03-19T13:40:30.749879Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"gen_optimizer = keras.optimizers.SGD(\n    learning_rate = 0.0001,\n    clipvalue = 1.0,\n    weight_decay = 1e-4)\n\ndisc_optimizer = keras.optimizers.SGD(\n    learning_rate = 0.0001,\n    clipvalue = 1.0,\n    weight_decay = 1e-4)\n\ncr_en_loss = keras.losses.BinaryCrossentropy(from_logits = True)","metadata":{"execution":{"iopub.status.busy":"2024-03-19T13:55:08.886104Z","iopub.execute_input":"2024-03-19T13:55:08.886774Z","iopub.status.idle":"2024-03-19T13:55:08.895367Z","shell.execute_reply.started":"2024-03-19T13:55:08.886740Z","shell.execute_reply":"2024-03-19T13:55:08.894591Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def generator_loss(fake_output):\n    return cr_en_loss(tf.ones_like(fake_output), fake_output)\n\ndef discriminator_loss(real_output, fake_output):\n    real_loss = cr_en_loss(tf.ones_like(real_output), real_output)\n    fake_loss = cr_en_loss(tf.zeros_like(fake_output), fake_output)\n    return real_loss + fake_loss","metadata":{"execution":{"iopub.status.busy":"2024-03-19T13:55:12.330101Z","iopub.execute_input":"2024-03-19T13:55:12.330479Z","iopub.status.idle":"2024-03-19T13:55:12.335954Z","shell.execute_reply.started":"2024-03-19T13:55:12.330435Z","shell.execute_reply":"2024-03-19T13:55:12.335014Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##**Build Training Steps**","metadata":{}},{"cell_type":"code","source":"def training_steps(images):\n    noise = np.random.normal(0, 1, (batch_size, latent_dim))\n    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n        generated_img = generator(noise)\n\n        fake_output = discriminator(generated_img)\n        real_output = discriminator(images)\n\n        gen_loss = generator_loss(fake_output)\n        disc_loss = discriminator_loss(real_output, fake_output)\n\n    gradient_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n    gradient_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n\n    gen_optimizer.apply_gradients(zip(gradient_of_generator,generator.trainable_variables))\n    disc_optimizer.apply_gradients(zip(gradient_of_discriminator, discriminator.trainable_variables))\n\n    loss = {'gen loss':gen_loss,\n           'disc loss': disc_loss}\n\n    return loss","metadata":{"execution":{"iopub.status.busy":"2024-03-19T13:55:15.474285Z","iopub.execute_input":"2024-03-19T13:55:15.475021Z","iopub.status.idle":"2024-03-19T13:55:15.482187Z","shell.execute_reply.started":"2024-03-19T13:55:15.474988Z","shell.execute_reply":"2024-03-19T13:55:15.481235Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import time\ndef train(epochs,dataset):\n\n    for epoch in range(epochs):\n        start = time.time()\n        print(\"\\nEpoch : {}\".format(epoch + 1))\n        for images in tqdm(dataset):\n            loss = training_steps(images)\n        print(\" Time:{}\".format(np.round(time.time() - start),2))\n        print(\"Generator Loss: {} Discriminator Loss: {}\".format(loss['gen loss'],loss['disc loss']))","metadata":{"execution":{"iopub.status.busy":"2024-03-19T13:55:18.881860Z","iopub.execute_input":"2024-03-19T13:55:18.882774Z","iopub.status.idle":"2024-03-19T13:55:18.888694Z","shell.execute_reply.started":"2024-03-19T13:55:18.882738Z","shell.execute_reply":"2024-03-19T13:55:18.887706Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##**Train the Dataset**\nif ~100 epochs use to get better results ","metadata":{}},{"cell_type":"code","source":"train(40, dataset)","metadata":{"execution":{"iopub.status.busy":"2024-03-19T13:55:23.780430Z","iopub.execute_input":"2024-03-19T13:55:23.780829Z","iopub.status.idle":"2024-03-19T15:28:44.461119Z","shell.execute_reply.started":"2024-03-19T13:55:23.780797Z","shell.execute_reply":"2024-03-19T15:28:44.460004Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_generated_images(square = 5, epochs = 0):\n    \n    \n  plt.figure(figsize = (10,10))\n  for i in range(square * square):\n    if epochs != 0:    \n        if(i == square //2):\n            plt.title(\"Generated Image at Epoch:{}\\n\".format(epochs), fontsize = 32, color = 'black')\n    plt.subplot(square, square, i+1)\n    noise = np.random.normal(0,1,(1,latent_dim))\n    img = generator(noise)\n    plt.imshow(np.clip((img[0,...]+1)/2, 0, 1))\n    \n    plt.xticks([])\n    plt.yticks([])\n    plt.grid()","metadata":{"execution":{"iopub.status.busy":"2024-03-19T15:30:16.509867Z","iopub.execute_input":"2024-03-19T15:30:16.510622Z","iopub.status.idle":"2024-03-19T15:30:16.518175Z","shell.execute_reply.started":"2024-03-19T15:30:16.510583Z","shell.execute_reply":"2024-03-19T15:30:16.517125Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_generated_images(4)","metadata":{"execution":{"iopub.status.busy":"2024-03-19T15:30:52.572262Z","iopub.execute_input":"2024-03-19T15:30:52.572635Z","iopub.status.idle":"2024-03-19T15:30:53.969812Z","shell.execute_reply.started":"2024-03-19T15:30:52.572609Z","shell.execute_reply":"2024-03-19T15:30:53.968752Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"At least 100 epochs Train to get better  results ","metadata":{}}]}